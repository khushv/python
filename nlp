# https://www.reddit.com/r/netsec/wiki/start

from os import listdir
from os.path import splitext

def read_file(filename):
    "Read the contents of FILENAME and return as a string."
    infile = open(filename, encoding="utf8") # windows users should use codecs.open after importing codecs
    contents = infile.read()
    infile.close()
    return contents
	
def list_textfiles(directory):
    "Return a list of filenames ending in '.txt' in DIRECTORY."
    textfiles = []
    for filename in listdir(directory):
        if filename.endswith(".txt"):
            textfiles.append(directory + "/" + filename)
    return textfiles

print("hello")

'''
for filepath in list_textfiles("gutenberg/training"):
    text = read_file(filepath)
    print(filepath +  " has " + str(len(text)) + " characters.")
	
'''

def end_of_sentence_marker(character):
	end_of_sentence = ".?!"
	if character in end_of_sentence:
		return True
	else:
		return False

'''
print("done")
print(end_of_sentence_marker("?") == True)
print(end_of_sentence_marker("a") == False)

'''


def split_sentences(text):
	#splits sentences based on .?!
	sentences = []
	start = 0
	for index, character in enumerate(text):
		if end_of_sentence_marker(character):
			sentence = text[start:index+1]
			sentences.append(sentence)
			start = index + 1
	return sentences


def tokenize(text):
	"""Transform TEXT into a list of sentences. Lowercase 
    each sentence and remove all punctuation. Finally split each
    sentence into a list of words."""
	clean = []
	sentences = split_sentences(text)
	for sentence in sentences:
		temp = sentence.lower().replace(",", "").replace("/", "").replace("!", "").replace(".", "").replace("?", "").replace("?", "").split()
		clean.append(temp)
	return clean


def clean_arabian(directory):
	corpus = []
	list_text_files = list_textfiles(directory)
	for file in list_text_files:
		temp = read_file(file)
		corpus.append(tokenize(temp))
	return corpus


def remove_ext(filename):
	#returns filename witout ext given FILENAME
	token = splitext(filename)
	return token[0]
	
'''
print(remove_ext("data/arabian_nights/1.txt") == "data/arabian_nights/1")
print(remove_ext("ridiculous_selfie.jpg") == "ridiculous_selfie")	
'''



	
	

